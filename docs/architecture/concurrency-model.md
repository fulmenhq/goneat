---
title: "Concurrency Model"
description: "Budgeted, layered concurrency and sharding strategy for goneat"
author: "Code Scout (@code-scout)"
date: "2025-08-31"
status: "proposal"
tags: ["concurrency","architecture","performance","planning"]
---

## Scope and assumptions
- Single-process execution (initial assumption). Concurrency coordination happens in-process.
- Assess orchestrates categories; individual GroupNeat commands (e.g., security) may perform intra-category parallelism.
- Future multi-process support will extend the same model via a shared token manager.

## Goals
- Predictable, scalable execution across large repos
- Prevent oversubscription when categories run concurrently
- Maximize real-world throughput via sharding and scope reduction (diff-based, staged-only)

## Layers of concurrency
1) Category-level (Assess engine)
- Assess runs categories (format, lint, security, etc.) with a worker-pool sized by CPU percentage (`--concurrency`, `--concurrency-percent`).
- Budget is a total token count representing available parallel capacity for the process.

2) Runner-level (Command-specific sharding)
- Runners (e.g., security) shard work into sub-units (packages/directories/files) and run with a bounded pool sized from the budget.
- Sharding is language/tool aware (e.g., Go packages via `go list`).

## Budgeting model (single-process)
- Total tokens = floor(cores * concurrency_percent/100), min 1.
- When N categories are active concurrently, each runner uses a bounded share of tokens (default: equal split; phase B/C can refine).
- If engine runs categories sequentially, the active runner can use the full token budget.

## Sharding priorities
- Scope first: reduce work via staged-only and diff-base (changed files/packages only).
- Shard second: split remaining work by natural boundaries (packages/directories/files) for parallel execution.
- Aggregate last: normalize tool outputs into the SSOT JSON.

## Security example (current implementation)
- Parallel tools: `gosec` (code) and `govulncheck` (deps) run concurrently.
- Sharded gosec: directory shards with a bounded worker pool sized from assess CPU%.
- Conservative default: when scope unknown, fall back to a single `./...` shard; diff/staged unlocks multiple shards.

## Shared utilities (near-term)
- Sharding helpers: standardize directory/package/file shard derivation across commands.
  - Go: `go list ./...` â†’ package dirs; map changed files to packages.
  - Respect `.goneatignore` and content-type filters.
- Dispatcher reuse: prefer `pkg/work/dispatcher` for shard execution to standardize progress reporting and metrics.

## Telemetry (later)
- Per-runner: runtime, shard count, pool size, queue wait, retry counts.
- Per-category: aggregate runtimes, throughput, token utilization.
- End-to-end: wall time vs. CPU budget; health of parallelization strategy across categories.

## Multi-process (future)
- Replace in-process token pool with a lightweight shared token manager (file/lock/semaphore-based) to coordinate across processes.
- Same budgeting semantics; category/runner layers remain unchanged.

## Testing strategy
- Large repository fixtures (monorepo-like): verify wall-time reduction with diff-based scope and sharding.
- Mixed-category assessments: ensure budget prevents oversubscription (stable CPU usage).
- Failure modes: per-shard retries (1x), resilient aggregation on partial failures.

## Next steps
- Deepen sharding for Go (`go list` based) and make helpers reusable across commands.
- Wire runners to `pkg/work/dispatcher` for consistent execution and progress.
- Introduce a minimal concurrency manager interface; have assess supply budgets to runners.

---
Generated by Code Scout under supervision of @3leapsdave